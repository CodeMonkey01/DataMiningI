{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeMonkey01/DataMiningI/blob/main/ANN/Option_A/ANN_with_BERT_add_BERT_seperator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oym-u7JY-lc"
      },
      "source": [
        "# ANN with BERT\n",
        "In this notebook I tried to solve the classification model with an ANN based on pretrained BERT layers.\n",
        "\n",
        "This notebook shows the preprocessing and hyperparameter selection process. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o41yey4xPvVp",
        "outputId": "52e0269b-61d7-4f70-8d49-8869a0368b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive\n",
            "Thu May 26 20:28:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd '/content/drive/MyDrive/'\n",
        "\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "except ImportError as e:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPNfsRkESPvi",
        "outputId": "e10a7ed0-bd1a-4fac-e9d1-f4f2b36c11c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 9.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.10,>=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 97.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.46.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.0 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install tensorflow_hub\n",
        "!pip install transformers\n",
        "#!pip install scikeras[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HUKHIT8hSOAH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Iop3r0LP7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "e985fb3e-711f-442a-df92-5f6ae094a843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text   humor\n",
              "count                                              200000  200000\n",
              "unique                                             200000       2\n",
              "top     Joe biden rules out 2020 bid: 'guys, i'm not r...   False\n",
              "freq                                                    1  100000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9eb9c65c-6337-4c99-87d5-4cc1acf6d106\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000</td>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>200000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eb9c65c-6337-4c99-87d5-4cc1acf6d106')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9eb9c65c-6337-4c99-87d5-4cc1acf6d106 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9eb9c65c-6337-4c99-87d5-4cc1acf6d106');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_raw = pd.read_csv('/content/drive/MyDrive/Data Mining/dataset.txt')\n",
        "df_raw.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ypD9eaqv5CI6"
      },
      "outputs": [],
      "source": [
        "# todo --> take (random) sample to speed up training\n",
        "df_sampled = df_raw.sample(20_000)\n",
        "df = df_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12R2RwOjS9-O"
      },
      "source": [
        "# Check for imbalance\n",
        "The dataset is equally balanced. Therefore, we do not need to rebalance the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvW_6M_VSuhG",
        "outputId": "1806699b-5e81-4b67-cd56-4445f92b38ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True     10053\n",
            "False     9947\n",
            "Name: humor, dtype: int64\n",
            "False    100000\n",
            "True     100000\n",
            "Name: humor, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_sampled[\"humor\"].value_counts())\n",
        "print(df[\"humor\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4KqkTrKTi5u"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "As wrote in the paper, we tried out different preprocessing approaches for BERT. \n",
        "\n",
        "1.   Stop word removal\n",
        "2.   Stemming\n",
        "3.   Seperator / Special tokens\n",
        "\n",
        "We tried these preprocessing independently and together. After testing each method (or combined with others) we found out that option 3 (\"Seperator / Special tokens) is working the best for BERT and this binary classification problem. The code for the other preprocessing methods is listed below.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform class from Boolean to integer value\n",
        "df_sampled['class']=df_sampled['humor'].apply(lambda x: 1 if x==True else 0)\n",
        "df['class']=df['humor'].apply(lambda x: 1 if x==True else 0)"
      ],
      "metadata": {
        "id": "c9JX8UBKedyr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 1 \n",
        "Stop word removal"
      ],
      "metadata": {
        "id": "HbKZFVcHeWZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "df['stop_word']=df['text'].apply(lambda x: remove_stopwords(x))"
      ],
      "metadata": {
        "id": "XeBZ9JyReZmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2\n",
        "Stemming"
      ],
      "metadata": {
        "id": "--UXMc9zemJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df['stemmed']=df['text'].apply(lambda x: ' '.join([ps.stem(y) for y in token_pattern.findall(x)]))"
      ],
      "metadata": {
        "id": "FMvnVEHcen2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 3 (WE USED THIS)\n",
        "Seperator and Special tokens"
      ],
      "metadata": {
        "id": "HXilaCnnd83v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4l7ycCbR0Zoe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c7b4a9521aa94ee9b9eef12fd6096da1",
            "740260148dd64d39896b2e9e0b625355",
            "94638bdc749449aab6bc8b5695910f48",
            "c33d539aa06543c1a06bd515eb37aea2",
            "92d06e0207bf4a2da666030932fb22cf",
            "d60e5a0301064d50857dbfc85f691014",
            "0e0b8ed2145342e78bf6050f12c2d0ab",
            "f21ed56c72994aa48c8514a175bf8ed1",
            "6de109c73e744be393b7d2e6ba3cb812",
            "677a8b56b75f4708b4c0c451f0196c90",
            "16249a5f67fb497ea1b5a9600249611b",
            "89004cadb6ba4b659789a0d9067f608f",
            "58fe41ee7b5e4b68b4250c2a37e5d9c0",
            "da96936c40674aa48d0c1b08e0c903da",
            "1f61b4c3deac46afa7260d198de789df",
            "492134850a2c4bd8bcf2f3113b385981",
            "68f2b06a8f354e61a9ca24777ee59896",
            "844db5015fdf4c939ade055e6bc16504",
            "a05d0855cadd480bbc2029631a1a7f1d",
            "83dd64e052ce4a3f85d05bef0e3b0802",
            "cae5e7deafb44a488f772098c869fde3",
            "beeec6138afb47d1b4cbf776c22ef709",
            "89de322b266f445ba47195a7315d8bdb",
            "b099cf64eec842b386ef955c34270735",
            "fbec7d3e9d644686ba733a983544f48f",
            "17dcbdeb96614310abbd76aaa6e50e15",
            "9ffdf04cfbab4b62a5aebe7381aefad9",
            "a962b96b834449e7812b1ebd9b1d67fc",
            "d049288f11ee437b952ca16e8c0a9670",
            "4e12044033be4fceab9f59836157cc8c",
            "20208cdbe6634e4d81fbbf2f11eeec92",
            "61e21028de82483188cd497ef8ef9e0e",
            "ced37242f1f74347a6ff66e9ea165bdc"
          ]
        },
        "outputId": "18ada36f-16ad-4188-f6d0-5713768a1c60"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7b4a9521aa94ee9b9eef12fd6096da1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89004cadb6ba4b659789a0d9067f608f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89de322b266f445ba47195a7315d8bdb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "MAX_LEN = 128\n",
        "#pad_to_max_length=True,\n",
        "df_sampled['bert_preprocessed']=df_sampled['text'].apply(lambda x: \" \".join(list(tokenizer.convert_ids_to_tokens(tokenizer.encode(x, add_special_tokens=True, max_length=MAX_LEN, truncation=True)))))\n",
        "df['bert_preprocessed']=df['text'].apply(lambda x: \" \".join(list(tokenizer.convert_ids_to_tokens(tokenizer.encode(x, add_special_tokens=True, max_length=MAX_LEN, truncation=True)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 4\n",
        "Stemming + Stop word removal"
      ],
      "metadata": {
        "id": "bQEvHjR_e07P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "my_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "df['stemmed_stop_removed']=df['text'].apply(lambda x: ' '.join([ps.stem(y) for y in token_pattern.findall(x) if y not in my_stopwords]))"
      ],
      "metadata": {
        "id": "kGEJlApve5Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Info\n",
        "Because the preprocessing part was a long lasting process the code for the different methods (stop word removal, stemming) were just added to show how we actually did it. The results are NOT used, because in our interative process we found out that seperator and special tokens (Option 3) works by far the best. "
      ],
      "metadata": {
        "id": "Noz7DzbKe8dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ghGSvlxC3vme",
        "outputId": "1f38a893-f505-4235-ed8f-4a3e82afa8b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  humor  class  \\\n",
              "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False      0   \n",
              "1  Watch: darvish gave hitter whiplash with slow ...  False      0   \n",
              "2  What do you call a turtle without its shell? d...   True      1   \n",
              "3      5 reasons the 2016 election feels so personal  False      0   \n",
              "4  Pasco police shot mexican migrant from behind,...  False      0   \n",
              "\n",
              "                                   bert_preprocessed  \n",
              "0  [CLS] Joe bid ##en rules out 2020 bid : ' guys...  \n",
              "1  [CLS] Watch : da ##r ##vis ##h gave hitter whi...  \n",
              "2  [CLS] What do you call a turtle without its sh...  \n",
              "3  [CLS] 5 reasons the 2016 election feels so per...  \n",
              "4  [CLS] Pa ##sco police shot me ##xi ##can migra...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d74eb0e3-e717-4b32-a18e-7199044d98c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>class</th>\n",
              "      <th>bert_preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] Joe bid ##en rules out 2020 bid : ' guys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] Watch : da ##r ##vis ##h gave hitter whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>[CLS] What do you call a turtle without its sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] 5 reasons the 2016 election feels so per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>[CLS] Pa ##sco police shot me ##xi ##can migra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d74eb0e3-e717-4b32-a18e-7199044d98c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d74eb0e3-e717-4b32-a18e-7199044d98c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d74eb0e3-e717-4b32-a18e-7199044d98c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "krCAqw4ITnh8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create train test split for training\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['bert_preprocessed'], df['class'], test_size=0.4)\n",
        "X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(df_sampled['bert_preprocessed'], df_sampled['class'], test_size=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KTg_ROTveS"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "USX6Lts4T0ey"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wlFXYUGkT3xW"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embeding(sentences):\n",
        "    preprocessed_text = bert_preprocess(sentences)\n",
        "    return bert_encoder(preprocessed_text)['pooled_output']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nt0AWJEUGJg"
      },
      "source": [
        "## Test embedding\n",
        "Test word embedding from pretrained BERT model with a real sentence from dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1osx4LSXUECE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2985a09-2c41-4657-df14-7cca4ccde5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence:\n",
            "[CLS] Watch : da ##r ##vis ##h gave hitter whip ##lash with slow pitch [SEP]\n",
            "Test sentence (word embedding):\n",
            "tf.Tensor(\n",
            "[[-5.35017192e-01  4.20762599e-01  9.99616385e-01 -9.87604976e-01\n",
            "   9.07577336e-01  9.38914835e-01  9.45565760e-01 -9.93435681e-01\n",
            "  -9.48297083e-01 -5.15298069e-01  9.62185860e-01  9.95873511e-01\n",
            "  -9.98733640e-01 -9.99418557e-01  8.06529641e-01 -9.32940423e-01\n",
            "   9.81226981e-01 -5.10653913e-01 -9.99887168e-01 -6.48698688e-01\n",
            "  -7.84378171e-01 -9.99633610e-01  1.55686572e-01  9.82200027e-01\n",
            "   9.40321684e-01 -8.46317858e-02  9.75835562e-01  9.99889851e-01\n",
            "   6.13145173e-01 -1.26248568e-01  2.51276761e-01 -9.81639445e-01\n",
            "   8.09462667e-01 -9.98223543e-01  1.50366932e-01  3.93522352e-01\n",
            "   7.17029512e-01 -1.49403870e-01  7.88604319e-01 -9.39887047e-01\n",
            "  -4.89151835e-01 -6.31983817e-01  5.66573143e-01 -4.94452208e-01\n",
            "   8.81204724e-01  6.84452876e-02 -9.58826672e-03 -9.67185646e-02\n",
            "   1.65023580e-02  9.99337792e-01 -9.00641918e-01  9.42173600e-01\n",
            "  -9.95904267e-01  9.58484948e-01  9.90067661e-01  3.69312465e-01\n",
            "   9.91070330e-01  1.48830131e-01 -9.98860657e-01 -3.10904197e-02\n",
            "   9.51409519e-01  2.44244069e-01  8.48620415e-01  5.57564422e-02\n",
            "   2.62247175e-01 -3.05142790e-01 -9.13071930e-01  2.18911842e-01\n",
            "  -3.81117761e-01  2.06582844e-01 -1.41579717e-01  2.90041596e-01\n",
            "   9.50619638e-01 -8.56413901e-01 -2.60840990e-02 -8.43885362e-01\n",
            "   1.09934919e-01 -9.99742627e-01  8.95227611e-01  9.99870360e-01\n",
            "   7.98925698e-01 -9.99285340e-01  9.86711442e-01 -2.30005056e-01\n",
            "  -7.10057020e-01  7.45571434e-01 -9.98670876e-01 -9.98381853e-01\n",
            "  -1.65022369e-02 -2.74416775e-01  9.38256741e-01 -9.76439893e-01\n",
            "   6.88733578e-01 -8.51797163e-01  9.99870658e-01 -9.19412971e-01\n",
            "  -1.99053407e-01  2.44063288e-01  9.69148040e-01 -8.39655995e-01\n",
            "  -4.79834318e-01  9.56493974e-01  9.98681366e-01 -9.94297206e-01\n",
            "   9.98583257e-01  6.89674795e-01 -9.04506803e-01 -8.87737930e-01\n",
            "   8.14806759e-01 -2.29160972e-02  9.75017905e-01 -9.52407718e-01\n",
            "  -9.11771536e-01 -1.23137922e-03  9.68061030e-01 -9.29213047e-01\n",
            "   9.76632059e-01  6.20052755e-01 -1.78275496e-01  9.99930382e-01\n",
            "  -9.70621407e-02  9.23696101e-01  9.96157885e-01  6.66754603e-01\n",
            "  -8.48726034e-01 -2.11425543e-01 -5.28262019e-01  9.04666901e-01\n",
            "  -6.23948932e-01 -5.48378117e-02  7.36689448e-01 -9.84264970e-01\n",
            "  -9.96363044e-01  9.98936594e-01 -1.24586076e-01  9.99882698e-01\n",
            "  -9.98329103e-01  9.90805149e-01 -9.99844968e-01 -9.27861929e-01\n",
            "  -6.17895901e-01 -1.29475921e-01 -9.80943501e-01 -1.84301257e-01\n",
            "   9.74621058e-01 -1.73376640e-04 -9.34936762e-01 -7.76385546e-01\n",
            "   7.01734960e-01 -8.90826702e-01  4.53875571e-01  6.92001939e-01\n",
            "  -9.04717863e-01  8.91798675e-01  9.97822046e-01  9.47262645e-01\n",
            "   9.65469658e-01  1.79951474e-01 -9.38679159e-01  8.44683945e-01\n",
            "   9.76334155e-01 -9.98450935e-01  8.87366831e-01 -9.93271828e-01\n",
            "   9.98344183e-01  9.38822627e-01  8.48308206e-01 -9.97162223e-01\n",
            "   9.99740779e-01 -7.12664187e-01 -1.46093652e-01  1.91065282e-01\n",
            "  -1.68224916e-01 -9.98897195e-01  3.76985908e-01  3.71133685e-01\n",
            "   4.41781342e-01  9.98580873e-01 -9.89504755e-01  9.98306811e-01\n",
            "   5.30635595e-01  2.47178182e-01  6.61438406e-01  9.99009967e-01\n",
            "  -9.91351306e-01 -9.44182992e-01 -9.74348783e-01  3.05561393e-01\n",
            "   7.92010486e-01  8.10636342e-01  5.40047765e-01  9.10426140e-01\n",
            "   9.97960389e-01  1.80032626e-01 -9.94863689e-01 -3.66564810e-01\n",
            "   9.55275297e-01 -6.27354160e-02  9.99905944e-01 -5.56093693e-01\n",
            "  -9.99560654e-01 -6.89386129e-01  9.03988838e-01  9.14509058e-01\n",
            "  -2.65167505e-01  9.42430794e-01 -7.83456087e-01 -2.80775875e-01\n",
            "   9.91512656e-01 -9.07338321e-01  9.97584581e-01  4.26328093e-01\n",
            "   7.38046527e-01  6.47906601e-01  9.77627456e-01 -8.62222672e-01\n",
            "  -5.23748510e-02  1.46808743e-01 -7.35300958e-01  9.99669969e-01\n",
            "  -9.99027729e-01 -1.14383548e-01  1.79538071e-01 -9.92747784e-01\n",
            "  -9.95570540e-01  9.52153683e-01  1.10573329e-01 -7.06046045e-01\n",
            "  -1.84139237e-01  7.01660216e-01  1.93509951e-01  9.13560688e-01\n",
            "   9.81817722e-01 -6.66993141e-01 -6.81283116e-01 -9.99632418e-01\n",
            "  -9.95358109e-01 -4.93122786e-01 -9.63595152e-01  5.84301278e-02\n",
            "   5.55589497e-01 -1.04774997e-01 -8.38420033e-01 -9.98442352e-01\n",
            "   9.10597146e-01  7.81092763e-01 -9.31768060e-01 -1.59360394e-02\n",
            "  -6.79919958e-01 -9.98099208e-01  4.29592520e-01 -9.17318821e-01\n",
            "  -9.97086346e-01  9.99184787e-01 -6.71037912e-01  9.96531606e-01\n",
            "   8.73481810e-01 -9.88678396e-01  8.89560640e-01 -9.98689711e-01\n",
            "  -1.92969203e-01 -9.31600273e-01  4.26261544e-01  6.77845597e-01\n",
            "  -5.22899270e-01  7.90864304e-02  9.85585928e-01 -9.16018963e-01\n",
            "  -8.49889815e-01  8.32869649e-01 -9.99625564e-01  8.59397292e-01\n",
            "  -5.76233678e-02  9.97809112e-01  7.36885667e-01  5.04712835e-02\n",
            "   9.68721151e-01  9.55281556e-01 -9.78793085e-01 -9.99512494e-01\n",
            "   9.62681592e-01  7.11004078e-01 -9.91056561e-01 -9.24248546e-02\n",
            "   9.99783158e-01 -9.98057008e-01 -4.40248877e-01 -9.19121981e-01\n",
            "  -9.86741126e-01 -9.99166906e-01  3.97118151e-01 -8.52067649e-01\n",
            "   2.75592238e-01  9.58092451e-01  4.85107750e-01  2.40928784e-01\n",
            "   9.93815899e-01  9.36839759e-01  2.71275043e-01 -1.93674996e-01\n",
            "   2.93519953e-03 -9.55166578e-01 -8.28655601e-01  7.10591912e-01\n",
            "   2.25668475e-01 -9.99901235e-01  9.99613404e-01 -9.89054620e-01\n",
            "   9.22061682e-01  8.88935566e-01 -9.96382296e-01  7.15140879e-01\n",
            "   1.82675570e-01 -9.60003793e-01 -9.06837955e-02  9.99716938e-01\n",
            "   9.56423938e-01 -3.27752493e-02  1.50374889e-01  8.97378802e-01\n",
            "  -3.65235209e-01  7.53037155e-01 -8.34423780e-01 -6.64984047e-01\n",
            "   1.45233884e-01 -8.98579836e-01  9.90216970e-01  8.16355050e-01\n",
            "  -9.80855346e-01  9.96530771e-01 -2.50771120e-02  4.59839612e-01\n",
            "  -8.13782394e-01  7.75116742e-01  9.81897712e-01 -4.61061820e-02\n",
            "  -5.56947589e-01 -8.42009187e-02 -4.50251736e-02 -9.86864030e-01\n",
            "  -4.76555191e-02 -9.97026920e-01 -4.87868369e-01  9.07213807e-01\n",
            "   9.57185209e-01 -9.65736210e-01  9.31989670e-01 -1.20029293e-01\n",
            "   9.46265936e-01 -9.98202622e-01  9.99925911e-01 -9.81377900e-01\n",
            "   1.50179178e-01  7.62028635e-01 -8.21690857e-01 -4.06309217e-01\n",
            "   9.85572338e-01  9.90841389e-01  9.86651063e-01 -9.74130273e-01\n",
            "  -8.87494624e-01  6.08433545e-01  9.29698348e-01 -9.59337652e-01\n",
            "  -3.98532897e-02 -9.99361157e-01 -6.79673612e-01  9.93091524e-01\n",
            "   9.97158527e-01 -1.07422601e-02 -2.76821047e-01 -9.98046696e-01\n",
            "   9.04673636e-01 -8.65011990e-01 -9.16993380e-01 -3.00923511e-02\n",
            "  -8.57296586e-01  8.06987226e-01  9.98116493e-01 -7.46729732e-01\n",
            "   8.05824757e-01  1.47855967e-01 -9.58576083e-01  9.32743371e-01\n",
            "   9.06307340e-01  9.99492407e-01 -9.67168689e-01  5.45529962e-01\n",
            "   9.66559947e-01 -1.11090913e-01 -8.17496181e-01  3.90359581e-01\n",
            "   9.99299169e-01 -9.16362882e-01 -1.34007052e-01 -9.99001145e-01\n",
            "   1.13211889e-02 -5.50035357e-01 -6.21942170e-02 -6.86204612e-01\n",
            "  -4.25577024e-03 -8.52942586e-01  9.73936260e-01  3.60836506e-01\n",
            "   6.95320845e-01 -5.56074858e-01  9.27145302e-01 -4.85605896e-01\n",
            "   4.13851887e-02 -3.04994464e-01 -3.42873544e-01  4.18795466e-01\n",
            "   2.31610224e-01  9.54606950e-01 -9.17342842e-01  9.99402881e-01\n",
            "   1.65454254e-01 -9.99875784e-01 -9.97117281e-01 -8.45607460e-01\n",
            "  -9.99218047e-01  6.26991749e-01 -9.60544944e-01  9.75147545e-01\n",
            "   9.06821609e-01 -9.97963786e-01 -9.99228060e-01 -9.78137910e-01\n",
            "  -9.42711174e-01  8.28663647e-01  5.64214051e-01  1.69130191e-01\n",
            "   3.73212248e-01 -3.36276777e-02 -1.49862710e-02 -4.12755311e-01\n",
            "   1.59493964e-02 -8.84145141e-01 -5.09894907e-01 -9.97977555e-01\n",
            "   8.78216565e-01 -9.99845326e-01 -8.50878477e-01  9.98075366e-01\n",
            "  -9.97681081e-01 -9.55493569e-01 -8.91242206e-01 -7.55257905e-01\n",
            "  -7.05710530e-01  3.43185574e-01  9.65623498e-01 -3.39739203e-01\n",
            "  -7.03153610e-01 -9.98788178e-01  9.74514842e-01 -8.91486406e-01\n",
            "   7.69998804e-02 -9.32125807e-01 -9.59868968e-01  9.99439359e-01\n",
            "   9.14243817e-01 -1.35010421e-01 -2.15718951e-02 -9.98109818e-01\n",
            "   9.79778826e-01 -9.41846013e-01 -9.31570053e-01 -9.72268522e-01\n",
            "   5.66907674e-02 -7.83986926e-01 -9.99546945e-01  1.90117974e-02\n",
            "   9.95781064e-01  9.54445839e-01  9.73060310e-01  1.00120576e-02\n",
            "  -2.83198357e-01 -9.30365622e-01  9.26203430e-02 -9.99839664e-01\n",
            "   8.78815055e-01  9.26914632e-01 -9.62028980e-01 -7.82360196e-01\n",
            "   9.89955842e-01  9.54056144e-01 -9.54274714e-01 -9.81777310e-01\n",
            "   9.39615905e-01  2.29596227e-01  9.08003628e-01 -6.75679922e-01\n",
            "  -3.39487791e-01  3.16523224e-01 -3.18047628e-02 -9.82046783e-01\n",
            "  -8.98607731e-01  9.94701326e-01 -9.99070644e-01  9.63988721e-01\n",
            "   9.93788838e-01  9.98541176e-01 -2.48115852e-01  2.48158783e-01\n",
            "  -9.76782262e-01 -9.12416399e-01 -5.21510422e-01  2.96212584e-01\n",
            "  -9.99828815e-01  9.99716640e-01 -9.99902189e-01  6.17288768e-01\n",
            "  -6.64830685e-01  8.87295246e-01  9.79762852e-01 -4.36016828e-01\n",
            "  -9.99692321e-01 -9.99636233e-01  2.04445466e-01  2.27987632e-01\n",
            "   9.83186722e-01  2.81362504e-01  3.92821655e-02 -6.88369215e-01\n",
            "  -3.15895200e-01  9.93849576e-01 -6.24348164e-01 -6.42810583e-01\n",
            "  -9.98186648e-01  9.99299467e-01  4.12513137e-01 -9.97113526e-01\n",
            "   9.95699584e-01 -9.99012887e-01  9.24850285e-01  9.33892548e-01\n",
            "   8.02966356e-01  9.23611999e-01 -9.98929381e-01  9.99891460e-01\n",
            "  -9.99515772e-01  9.75430250e-01 -9.99902487e-01 -9.99168694e-01\n",
            "   9.99513447e-01 -9.85195518e-01 -7.44695604e-01 -9.99218881e-01\n",
            "  -9.97401297e-01  6.26854956e-01  6.77581504e-02 -5.41631043e-01\n",
            "   9.76423144e-01 -9.99591529e-01 -9.97185588e-01 -5.36202371e-01\n",
            "  -9.07074273e-01 -8.21829140e-01  9.95237172e-01 -7.60439932e-01\n",
            "   9.81160760e-01 -3.06310952e-01  9.21362817e-01  3.88551533e-01\n",
            "   9.98553216e-01  9.48494852e-01 -8.27219129e-01 -8.97024512e-01\n",
            "  -9.86603200e-01  9.63189900e-01 -6.16740465e-01  1.74503639e-01\n",
            "   9.39418614e-01  9.39102843e-02 -8.19198668e-01  2.83094406e-01\n",
            "  -9.95432794e-01  5.88800490e-01  2.13864282e-01  9.71018136e-01\n",
            "   8.87755275e-01  7.89489508e-01 -1.51462838e-01 -5.66730201e-01\n",
            "  -2.33601213e-01 -9.86621320e-01  4.40757096e-01 -9.99061584e-01\n",
            "   9.53616500e-01 -9.25544381e-01 -5.03022298e-02 -4.40555781e-01\n",
            "   1.51603803e-01 -8.72871757e-01  9.99163687e-01  9.96345639e-01\n",
            "  -9.31161821e-01 -4.09127139e-02  9.77197707e-01 -7.80712426e-01\n",
            "   9.61666644e-01 -9.88142550e-01  5.82269169e-02  9.75484490e-01\n",
            "  -4.75786984e-01  9.66794431e-01  1.37719840e-01  2.12882198e-02\n",
            "   9.79356110e-01 -9.88990784e-01 -8.82832944e-01 -5.97046196e-01\n",
            "   4.74125594e-01 -7.65268654e-02 -9.48739886e-01  3.15727033e-02\n",
            "   9.88101661e-01 -5.62055886e-01 -9.99334991e-01  8.59559894e-01\n",
            "  -9.98730540e-01 -3.66164185e-02  9.66156363e-01 -2.59213597e-01\n",
            "   9.99731839e-01 -8.98956180e-01  1.39373869e-01  6.28160164e-02\n",
            "  -9.99325812e-01 -9.98874664e-01  3.34480517e-02 -1.43971130e-01\n",
            "  -9.29060161e-01  9.99302447e-01 -2.43482724e-01  7.95323789e-01\n",
            "  -9.99611735e-01  2.94893980e-01  9.95358288e-01  1.87982067e-01\n",
            "   7.10202157e-01 -8.58350277e-01 -8.73435140e-01 -9.61547613e-01\n",
            "  -4.00970906e-01 -1.61751937e-02  8.74727905e-01 -9.16748762e-01\n",
            "  -7.47964263e-01 -9.33959246e-01  9.99871373e-01 -9.95567203e-01\n",
            "  -8.55984449e-01 -9.86110210e-01  6.89705849e-01  8.99757385e-01\n",
            "   4.05683905e-01  9.31761265e-02 -8.98029029e-01  9.64776754e-01\n",
            "  -9.11126316e-01  9.91410255e-01 -9.90924954e-01 -9.91556287e-01\n",
            "   9.99615014e-01  5.29672444e-01 -9.94008303e-01  1.54520348e-01\n",
            "  -2.80057311e-01  4.69871968e-01  1.64305910e-01  8.69591892e-01\n",
            "  -6.22273743e-01 -2.19804361e-01 -9.77997422e-01  7.54361331e-01\n",
            "  -8.46028566e-01 -9.76159751e-01 -2.88220614e-01 -2.19683707e-01\n",
            "  -9.09037650e-01  9.88211870e-01  9.47490931e-01  9.99829888e-01\n",
            "  -9.99299109e-01  7.26234853e-01 -1.15645742e-02  9.98006284e-01\n",
            "   3.63115817e-02 -5.96516609e-01  8.89188468e-01  9.99188125e-01\n",
            "  -7.32033849e-01  8.22089493e-01 -1.34585589e-01  7.56597798e-03\n",
            "   5.49238145e-01 -4.85766053e-01  9.97306764e-01 -9.19778943e-01\n",
            "   2.16825828e-01 -9.73992527e-01 -9.99776542e-01  9.99824524e-01\n",
            "   1.51887573e-02  9.84756112e-01  2.38878980e-01  6.75379217e-01\n",
            "  -5.84239542e-01  9.83710110e-01 -9.78426993e-01 -8.42456639e-01\n",
            "  -9.99926090e-01  1.93216413e-01 -9.45881367e-01 -9.85108674e-01\n",
            "  -2.00921059e-01  9.72701609e-01 -9.99160826e-01 -9.78884876e-01\n",
            "  -3.65773082e-01 -9.99905050e-01  8.69547904e-01 -9.85244691e-01\n",
            "  -9.09052491e-01 -9.73823428e-01  9.97548699e-01 -1.17513433e-01\n",
            "  -7.37642705e-01  9.63267267e-01 -9.11144853e-01  9.55872059e-01\n",
            "   8.89396131e-01 -4.84127462e-01  2.68008977e-01  4.72742580e-02\n",
            "  -8.24527383e-01 -9.93403912e-01 -8.88901830e-01 -9.53492522e-01\n",
            "   7.36558020e-01 -9.69480634e-01 -4.38868821e-01  9.95078206e-01\n",
            "   9.80600476e-01 -9.98772502e-01 -9.91212785e-01  9.93031144e-01\n",
            "   1.81243002e-01  9.82469261e-01 -2.67659187e-01 -9.99677479e-01\n",
            "  -9.99770939e-01 -4.34447499e-03  3.58200103e-01  9.88507271e-01\n",
            "  -2.46641204e-01  8.53221595e-01  5.19628584e-01 -5.27957737e-01\n",
            "   4.21582699e-01 -7.71286190e-01 -4.97936547e-01 -5.29796481e-01\n",
            "  -1.60554186e-01  9.99877095e-01 -8.40986907e-01  9.79987264e-01]], shape=(1, 768), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "test_sentence = df[\"bert_preprocessed\"][1]\n",
        "print(\"Test sentence:\")\n",
        "print(test_sentence)\n",
        "print(\"Test sentence (word embedding):\")\n",
        "print(get_sentence_embeding([test_sentence]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T06BUvCuUuJ8"
      },
      "source": [
        "# Build model\n",
        "\n",
        "```\n",
        "__________________________________________________________________________________________________\n",
        " Layer (type)                   Output Shape         Param #     Connected to                     \n",
        "==================================================================================================\n",
        " text (InputLayer)              [(None,)]            0           []                               \n",
        "                                                                                                  \n",
        " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
        "                                e, 128),                                                          \n",
        "                                 'input_type_ids':                                                \n",
        "                                (None, 128),                                                      \n",
        "                                 'input_word_ids':                                                \n",
        "                                (None, 128)}                                                      \n",
        "                                                                                                  \n",
        " keras_layer_1 (KerasLayer)     {'encoder_outputs':  108310273   ['keras_layer[1][0]',            \n",
        "                                 [(None, 128, 768),               'keras_layer[1][1]',            \n",
        "                                 (None, 128, 768),                'keras_layer[1][2]']            \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 (None, 128, 768)],                                               \n",
        "                                 'sequence_output':                                               \n",
        "                                 (None, 128, 768),                                                \n",
        "                                 'pooled_output': (                                               \n",
        "                                None, 768),                                                       \n",
        "                                 'default': (None,                                                \n",
        "                                768)}                                                             \n",
        "                                                                                                  \n",
        " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[1][13]']         \n",
        "                                                                                                  \n",
        " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
        "                                                                                                  \n",
        "==================================================================================================\n",
        "Total params: 108,311,042\n",
        "Trainable params: 769\n",
        "Non-trainable params: 108,310,273\n",
        "__________________________________________________________________________________________________\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rMwxDdFPQCiQ"
      },
      "outputs": [],
      "source": [
        "def build_model() -> tf.keras.Model:\n",
        "    # Bert layers\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessed_text = bert_preprocess(text_input)\n",
        "    outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "    # Neural network layers\n",
        "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output']) # dropout rate of 0.1 works the best\n",
        "    l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l) # other activation functions like softmax reduce the accuracy by A LOT\n",
        "\n",
        "    # Use inputs and outputs to construct a final model\n",
        "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXsa_dHHU1_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40383c7c-a825-4177-a50e-42f06e45f178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combinations: 54\n",
            "Try adam learning rate of: 0.001 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 86s 197ms/step - loss: 0.6018 - accuracy: 0.6802 - precision: 0.6776 - recall: 0.6943\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4738 - accuracy: 0.7978 - precision: 0.7951 - recall: 0.8054\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4163 - accuracy: 0.8330 - precision: 0.8299 - recall: 0.8400\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3801 - accuracy: 0.8500 - precision: 0.8509 - recall: 0.8507\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3586 - accuracy: 0.8549 - precision: 0.8539 - recall: 0.8583\n",
            "250/250 [==============================] - 50s 196ms/step - loss: 0.3370 - accuracy: 0.8656 - precision: 0.8964 - recall: 0.8237\n",
            "Try adam learning rate of: 0.001 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6041 - accuracy: 0.7521 - precision: 0.7580 - recall: 0.7402\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4739 - accuracy: 0.8033 - precision: 0.8001 - recall: 0.8115\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4133 - accuracy: 0.8315 - precision: 0.8276 - recall: 0.8397\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3811 - accuracy: 0.8478 - precision: 0.8466 - recall: 0.8516\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3580 - accuracy: 0.8568 - precision: 0.8558 - recall: 0.8599\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3397 - accuracy: 0.8634 - precision: 0.9016 - recall: 0.8126\n",
            "Try adam learning rate of: 0.001 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5839 - accuracy: 0.7675 - precision: 0.7740 - recall: 0.7552\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4639 - accuracy: 0.8128 - precision: 0.8087 - recall: 0.8221\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4136 - accuracy: 0.8325 - precision: 0.8325 - recall: 0.8347\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3806 - accuracy: 0.8464 - precision: 0.8443 - recall: 0.8515\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3578 - accuracy: 0.8524 - precision: 0.8506 - recall: 0.8570\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3369 - accuracy: 0.8676 - precision: 0.9010 - recall: 0.8229\n",
            "Try adam learning rate of: 0.001 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6130 - accuracy: 0.7463 - precision: 0.7505 - recall: 0.7375\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4778 - accuracy: 0.8022 - precision: 0.7958 - recall: 0.8158\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4147 - accuracy: 0.8361 - precision: 0.8335 - recall: 0.8422\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3855 - accuracy: 0.8476 - precision: 0.8470 - recall: 0.8505\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3643 - accuracy: 0.8554 - precision: 0.8538 - recall: 0.8596\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3362 - accuracy: 0.8744 - precision: 0.8774 - recall: 0.8674\n",
            "Try adam learning rate of: 0.001 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6432 - accuracy: 0.7270 - precision: 0.7237 - recall: 0.7336\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5270 - accuracy: 0.7742 - precision: 0.7715 - recall: 0.7829\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4696 - accuracy: 0.8052 - precision: 0.8018 - recall: 0.8139\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4232 - accuracy: 0.8310 - precision: 0.8268 - recall: 0.8397\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3959 - accuracy: 0.8425 - precision: 0.8398 - recall: 0.8487\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3826 - accuracy: 0.8439 - precision: 0.9033 - recall: 0.7666\n",
            "Try adam learning rate of: 0.001 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.7080 - accuracy: 0.6504 - precision: 0.6538 - recall: 0.6383\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.6476 - accuracy: 0.6271 - precision: 0.6246 - recall: 0.6473\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5993 - accuracy: 0.7002 - precision: 0.6960 - recall: 0.7166\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.5582 - accuracy: 0.7503 - precision: 0.7449 - recall: 0.7656\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.5263 - accuracy: 0.7732 - precision: 0.7674 - recall: 0.7878\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.4966 - accuracy: 0.8291 - precision: 0.8127 - recall: 0.8507\n",
            "Try adam learning rate of: 0.002 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 198ms/step - loss: 0.5443 - accuracy: 0.7692 - precision: 0.7612 - recall: 0.7840\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4035 - accuracy: 0.8337 - precision: 0.8323 - recall: 0.8381\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3592 - accuracy: 0.8523 - precision: 0.8510 - recall: 0.8561\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3445 - accuracy: 0.8567 - precision: 0.8589 - recall: 0.8555\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3169 - accuracy: 0.8684 - precision: 0.8683 - recall: 0.8702\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2875 - accuracy: 0.8875 - precision: 0.8883 - recall: 0.8838\n",
            "Try adam learning rate of: 0.002 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5433 - accuracy: 0.7929 - precision: 0.7925 - recall: 0.7933\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3992 - accuracy: 0.8393 - precision: 0.8368 - recall: 0.8454\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3588 - accuracy: 0.8540 - precision: 0.8528 - recall: 0.8576\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3366 - accuracy: 0.8621 - precision: 0.8609 - recall: 0.8656\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3194 - accuracy: 0.8681 - precision: 0.8681 - recall: 0.8697\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2977 - accuracy: 0.8826 - precision: 0.8503 - recall: 0.9257\n",
            "Try adam learning rate of: 0.002 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5515 - accuracy: 0.7940 - precision: 0.7821 - recall: 0.8147\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4065 - accuracy: 0.8370 - precision: 0.8346 - recall: 0.8429\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3625 - accuracy: 0.8482 - precision: 0.8487 - recall: 0.8495\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3360 - accuracy: 0.8632 - precision: 0.8620 - recall: 0.8666\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3209 - accuracy: 0.8689 - precision: 0.8673 - recall: 0.8729\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2931 - accuracy: 0.8857 - precision: 0.8647 - recall: 0.9118\n",
            "Try adam learning rate of: 0.002 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5575 - accuracy: 0.7849 - precision: 0.7757 - recall: 0.8011\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4176 - accuracy: 0.8306 - precision: 0.8306 - recall: 0.8329\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3691 - accuracy: 0.8473 - precision: 0.8470 - recall: 0.8498\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3479 - accuracy: 0.8573 - precision: 0.8595 - recall: 0.8561\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3283 - accuracy: 0.8622 - precision: 0.8629 - recall: 0.8631\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2955 - accuracy: 0.8838 - precision: 0.8753 - recall: 0.8921\n",
            "Try adam learning rate of: 0.002 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.6003 - accuracy: 0.7609 - precision: 0.7544 - recall: 0.7730\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4621 - accuracy: 0.8061 - precision: 0.8026 - recall: 0.8147\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4110 - accuracy: 0.8284 - precision: 0.8269 - recall: 0.8331\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3778 - accuracy: 0.8470 - precision: 0.8449 - recall: 0.8521\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3560 - accuracy: 0.8501 - precision: 0.8469 - recall: 0.8566\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3341 - accuracy: 0.8677 - precision: 0.8276 - recall: 0.9255\n",
            "Try adam learning rate of: 0.002 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 198ms/step - loss: 0.6797 - accuracy: 0.6861 - precision: 0.6741 - recall: 0.7196\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5964 - accuracy: 0.6947 - precision: 0.6901 - recall: 0.7127\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.5341 - accuracy: 0.7611 - precision: 0.7552 - recall: 0.7764\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4898 - accuracy: 0.7912 - precision: 0.7877 - recall: 0.8006\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4621 - accuracy: 0.8094 - precision: 0.8041 - recall: 0.8210\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.4280 - accuracy: 0.8446 - precision: 0.8258 - recall: 0.8694\n",
            "Try adam learning rate of: 0.003 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.5245 - accuracy: 0.7804 - precision: 0.7741 - recall: 0.7913\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3813 - accuracy: 0.8409 - precision: 0.8404 - recall: 0.8439\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3450 - accuracy: 0.8564 - precision: 0.8556 - recall: 0.8594\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3291 - accuracy: 0.8608 - precision: 0.8601 - recall: 0.8634\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3068 - accuracy: 0.8723 - precision: 0.8701 - recall: 0.8768\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2731 - accuracy: 0.8919 - precision: 0.8762 - recall: 0.9101\n",
            "Try adam learning rate of: 0.003 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5103 - accuracy: 0.8112 - precision: 0.8047 - recall: 0.8214\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3759 - accuracy: 0.8457 - precision: 0.8455 - recall: 0.8480\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3345 - accuracy: 0.8658 - precision: 0.8650 - recall: 0.8686\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3160 - accuracy: 0.8703 - precision: 0.8690 - recall: 0.8739\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3051 - accuracy: 0.8754 - precision: 0.8749 - recall: 0.8777\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2706 - accuracy: 0.8917 - precision: 0.9028 - recall: 0.8755\n",
            "Try adam learning rate of: 0.003 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.5334 - accuracy: 0.7998 - precision: 0.8005 - recall: 0.7981\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3828 - accuracy: 0.8454 - precision: 0.8427 - recall: 0.8515\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3445 - accuracy: 0.8562 - precision: 0.8551 - recall: 0.8596\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3202 - accuracy: 0.8689 - precision: 0.8688 - recall: 0.8707\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3062 - accuracy: 0.8741 - precision: 0.8729 - recall: 0.8773\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2904 - accuracy: 0.8842 - precision: 0.8444 - recall: 0.9391\n",
            "Try adam learning rate of: 0.003 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5203 - accuracy: 0.8033 - precision: 0.7902 - recall: 0.8257\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3843 - accuracy: 0.8415 - precision: 0.8374 - recall: 0.8497\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3455 - accuracy: 0.8545 - precision: 0.8534 - recall: 0.8579\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3196 - accuracy: 0.8683 - precision: 0.8689 - recall: 0.8692\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3163 - accuracy: 0.8686 - precision: 0.8666 - recall: 0.8730\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2764 - accuracy: 0.8903 - precision: 0.9013 - recall: 0.8740\n",
            "Try adam learning rate of: 0.003 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5859 - accuracy: 0.7731 - precision: 0.7735 - recall: 0.7717\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4294 - accuracy: 0.8239 - precision: 0.8226 - recall: 0.8284\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3797 - accuracy: 0.8395 - precision: 0.8371 - recall: 0.8452\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3555 - accuracy: 0.8493 - precision: 0.8474 - recall: 0.8540\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3398 - accuracy: 0.8577 - precision: 0.8570 - recall: 0.8604\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3001 - accuracy: 0.8841 - precision: 0.8852 - recall: 0.8800\n",
            "Try adam learning rate of: 0.003 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6680 - accuracy: 0.7087 - precision: 0.7044 - recall: 0.7185\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5622 - accuracy: 0.7345 - precision: 0.7294 - recall: 0.7502\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4973 - accuracy: 0.7825 - precision: 0.7758 - recall: 0.7979\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4516 - accuracy: 0.8162 - precision: 0.8111 - recall: 0.8270\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4288 - accuracy: 0.8182 - precision: 0.8122 - recall: 0.8303\n",
            "250/250 [==============================] - 52s 197ms/step - loss: 0.3939 - accuracy: 0.8531 - precision: 0.8754 - recall: 0.8199\n",
            "Try adam learning rate of: 0.004 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.4819 - accuracy: 0.8054 - precision: 0.8089 - recall: 0.7991\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3606 - accuracy: 0.8487 - precision: 0.8468 - recall: 0.8533\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3233 - accuracy: 0.8641 - precision: 0.8628 - recall: 0.8676\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3096 - accuracy: 0.8713 - precision: 0.8683 - recall: 0.8772\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.2897 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8825\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2749 - accuracy: 0.8866 - precision: 0.9311 - recall: 0.8325\n",
            "Try adam learning rate of: 0.004 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.4909 - accuracy: 0.8161 - precision: 0.8256 - recall: 0.8011\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3617 - accuracy: 0.8460 - precision: 0.8448 - recall: 0.8498\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3234 - accuracy: 0.8662 - precision: 0.8657 - recall: 0.8686\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3157 - accuracy: 0.8650 - precision: 0.8660 - recall: 0.8654\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.2962 - accuracy: 0.8778 - precision: 0.8793 - recall: 0.8775\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2865 - accuracy: 0.8830 - precision: 0.8373 - recall: 0.9477\n",
            "Try adam learning rate of: 0.004 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5042 - accuracy: 0.8123 - precision: 0.7922 - recall: 0.8464\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3602 - accuracy: 0.8487 - precision: 0.8465 - recall: 0.8540\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3226 - accuracy: 0.8666 - precision: 0.8670 - recall: 0.8677\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3066 - accuracy: 0.8702 - precision: 0.8690 - recall: 0.8734\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.2961 - accuracy: 0.8770 - precision: 0.8762 - recall: 0.8797\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2586 - accuracy: 0.8971 - precision: 0.9052 - recall: 0.8848\n",
            "Try adam learning rate of: 0.004 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5088 - accuracy: 0.8106 - precision: 0.8088 - recall: 0.8133\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3689 - accuracy: 0.8472 - precision: 0.8470 - recall: 0.8495\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3308 - accuracy: 0.8656 - precision: 0.8648 - recall: 0.8684\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3107 - accuracy: 0.8718 - precision: 0.8701 - recall: 0.8758\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3081 - accuracy: 0.8687 - precision: 0.8677 - recall: 0.8717\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2638 - accuracy: 0.8953 - precision: 0.8807 - recall: 0.9118\n",
            "Try adam learning rate of: 0.004 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5649 - accuracy: 0.7811 - precision: 0.7771 - recall: 0.7877\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4190 - accuracy: 0.8198 - precision: 0.8206 - recall: 0.8210\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3751 - accuracy: 0.8397 - precision: 0.8357 - recall: 0.8480\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3434 - accuracy: 0.8552 - precision: 0.8547 - recall: 0.8578\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3363 - accuracy: 0.8574 - precision: 0.8580 - recall: 0.8584\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2875 - accuracy: 0.8864 - precision: 0.8882 - recall: 0.8813\n",
            "Try adam learning rate of: 0.004 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6551 - accuracy: 0.7153 - precision: 0.7120 - recall: 0.7225\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5353 - accuracy: 0.7584 - precision: 0.7518 - recall: 0.7754\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4695 - accuracy: 0.7985 - precision: 0.7932 - recall: 0.8105\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4318 - accuracy: 0.8153 - precision: 0.8127 - recall: 0.8221\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4056 - accuracy: 0.8299 - precision: 0.8276 - recall: 0.8357\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.3715 - accuracy: 0.8602 - precision: 0.8298 - recall: 0.9028\n",
            "Try adam learning rate of: 0.005 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.4965 - accuracy: 0.8001 - precision: 0.7871 - recall: 0.8224\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3484 - accuracy: 0.8536 - precision: 0.8521 - recall: 0.8576\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3165 - accuracy: 0.8695 - precision: 0.8714 - recall: 0.8686\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3107 - accuracy: 0.8680 - precision: 0.8661 - recall: 0.8724\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.2889 - accuracy: 0.8832 - precision: 0.8825 - recall: 0.8855\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2992 - accuracy: 0.8754 - precision: 0.8184 - recall: 0.9616\n",
            "Try adam learning rate of: 0.005 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.4926 - accuracy: 0.8037 - precision: 0.7835 - recall: 0.8387\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3552 - accuracy: 0.8483 - precision: 0.8484 - recall: 0.8503\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3208 - accuracy: 0.8657 - precision: 0.8660 - recall: 0.8669\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3052 - accuracy: 0.8734 - precision: 0.8726 - recall: 0.8762\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2963 - accuracy: 0.8747 - precision: 0.8749 - recall: 0.8760\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2925 - accuracy: 0.8775 - precision: 0.9474 - recall: 0.7967\n",
            "Try adam learning rate of: 0.005 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4713 - accuracy: 0.8184 - precision: 0.8382 - recall: 0.7887\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3530 - accuracy: 0.8477 - precision: 0.8490 - recall: 0.8478\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3185 - accuracy: 0.8665 - precision: 0.8648 - recall: 0.8705\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3060 - accuracy: 0.8706 - precision: 0.8710 - recall: 0.8717\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2912 - accuracy: 0.8809 - precision: 0.8805 - recall: 0.8830\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2647 - accuracy: 0.8891 - precision: 0.9298 - recall: 0.8394\n",
            "Try adam learning rate of: 0.005 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4915 - accuracy: 0.8134 - precision: 0.8230 - recall: 0.7981\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3618 - accuracy: 0.8458 - precision: 0.8458 - recall: 0.8480\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3186 - accuracy: 0.8699 - precision: 0.8701 - recall: 0.8714\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3086 - accuracy: 0.8672 - precision: 0.8668 - recall: 0.8694\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2988 - accuracy: 0.8763 - precision: 0.8779 - recall: 0.8758\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2547 - accuracy: 0.8972 - precision: 0.8934 - recall: 0.8997\n",
            "Try adam learning rate of: 0.005 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.5525 - accuracy: 0.7882 - precision: 0.7828 - recall: 0.7971\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4027 - accuracy: 0.8288 - precision: 0.8264 - recall: 0.8347\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3593 - accuracy: 0.8481 - precision: 0.8471 - recall: 0.8515\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3336 - accuracy: 0.8587 - precision: 0.8565 - recall: 0.8636\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3238 - accuracy: 0.8641 - precision: 0.8622 - recall: 0.8684\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2806 - accuracy: 0.8873 - precision: 0.8688 - recall: 0.9096\n",
            "Try adam learning rate of: 0.005 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.6696 - accuracy: 0.7067 - precision: 0.6991 - recall: 0.7250\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.5346 - accuracy: 0.7475 - precision: 0.7451 - recall: 0.7565\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4568 - accuracy: 0.8051 - precision: 0.7996 - recall: 0.8170\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4168 - accuracy: 0.8258 - precision: 0.8211 - recall: 0.8356\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3969 - accuracy: 0.8291 - precision: 0.8265 - recall: 0.8354\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.3569 - accuracy: 0.8644 - precision: 0.8453 - recall: 0.8886\n",
            "Try adam learning rate of: 0.006 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4639 - accuracy: 0.8159 - precision: 0.8072 - recall: 0.8296\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3418 - accuracy: 0.8569 - precision: 0.8576 - recall: 0.8578\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3213 - accuracy: 0.8627 - precision: 0.8611 - recall: 0.8666\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2960 - accuracy: 0.8782 - precision: 0.8766 - recall: 0.8818\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3126 - accuracy: 0.8680 - precision: 0.8686 - recall: 0.8689\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.4046 - accuracy: 0.8219 - precision: 0.7411 - recall: 0.9838\n",
            "Try adam learning rate of: 0.006 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4899 - accuracy: 0.7819 - precision: 0.7466 - recall: 0.8531\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3450 - accuracy: 0.8528 - precision: 0.8504 - recall: 0.8583\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3213 - accuracy: 0.8650 - precision: 0.8631 - recall: 0.8694\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2997 - accuracy: 0.8755 - precision: 0.8744 - recall: 0.8785\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.2906 - accuracy: 0.8808 - precision: 0.8804 - recall: 0.8830\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2810 - accuracy: 0.8846 - precision: 0.9486 - recall: 0.8108\n",
            "Try adam learning rate of: 0.006 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4823 - accuracy: 0.8138 - precision: 0.8314 - recall: 0.7868\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3423 - accuracy: 0.8566 - precision: 0.8577 - recall: 0.8570\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3206 - accuracy: 0.8648 - precision: 0.8645 - recall: 0.8671\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2993 - accuracy: 0.8746 - precision: 0.8746 - recall: 0.8762\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2970 - accuracy: 0.8751 - precision: 0.8737 - recall: 0.8785\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2448 - accuracy: 0.9013 - precision: 0.9047 - recall: 0.8947\n",
            "Try adam learning rate of: 0.006 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4977 - accuracy: 0.8138 - precision: 0.8128 - recall: 0.8149\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3579 - accuracy: 0.8459 - precision: 0.8474 - recall: 0.8458\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3268 - accuracy: 0.8618 - precision: 0.8598 - recall: 0.8662\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3135 - accuracy: 0.8689 - precision: 0.8682 - recall: 0.8715\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3156 - accuracy: 0.8627 - precision: 0.8608 - recall: 0.8671\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.4728 - accuracy: 0.7896 - precision: 0.9814 - recall: 0.5860\n",
            "Try adam learning rate of: 0.006 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.5416 - accuracy: 0.7499 - precision: 0.7960 - recall: 0.6716\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3936 - accuracy: 0.8307 - precision: 0.8287 - recall: 0.8362\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3558 - accuracy: 0.8497 - precision: 0.8485 - recall: 0.8535\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3273 - accuracy: 0.8617 - precision: 0.8624 - recall: 0.8624\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3215 - accuracy: 0.8657 - precision: 0.8656 - recall: 0.8676\n",
            "250/250 [==============================] - 50s 196ms/step - loss: 0.2836 - accuracy: 0.8873 - precision: 0.8529 - recall: 0.9331\n",
            "Try adam learning rate of: 0.006 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 197ms/step - loss: 0.6394 - accuracy: 0.7280 - precision: 0.7173 - recall: 0.7521\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.5089 - accuracy: 0.7698 - precision: 0.7668 - recall: 0.7792\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.4372 - accuracy: 0.8138 - precision: 0.8085 - recall: 0.8251\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4062 - accuracy: 0.8282 - precision: 0.8258 - recall: 0.8342\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3822 - accuracy: 0.8359 - precision: 0.8338 - recall: 0.8414\n",
            "250/250 [==============================] - 52s 198ms/step - loss: 0.3416 - accuracy: 0.8700 - precision: 0.8587 - recall: 0.8825\n",
            "Try adam learning rate of: 0.007 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 198ms/step - loss: 0.4796 - accuracy: 0.8138 - precision: 0.8085 - recall: 0.8220\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3362 - accuracy: 0.8566 - precision: 0.8558 - recall: 0.8596\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3160 - accuracy: 0.8693 - precision: 0.8709 - recall: 0.8689\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2952 - accuracy: 0.8757 - precision: 0.8762 - recall: 0.8765\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2955 - accuracy: 0.8760 - precision: 0.8752 - recall: 0.8787\n",
            "250/250 [==============================] - 50s 197ms/step - loss: 0.2398 - accuracy: 0.9038 - precision: 0.8971 - recall: 0.9098\n",
            "Try adam learning rate of: 0.007 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.5056 - accuracy: 0.8105 - precision: 0.8080 - recall: 0.8142\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3343 - accuracy: 0.8583 - precision: 0.8593 - recall: 0.8586\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3162 - accuracy: 0.8698 - precision: 0.8692 - recall: 0.8724\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3116 - accuracy: 0.8674 - precision: 0.8669 - recall: 0.8699\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2849 - accuracy: 0.8845 - precision: 0.8837 - recall: 0.8870\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2467 - accuracy: 0.9019 - precision: 0.8795 - recall: 0.9290\n",
            "Try adam learning rate of: 0.007 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.4637 - accuracy: 0.8261 - precision: 0.8171 - recall: 0.8399\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 199ms/step - loss: 0.3341 - accuracy: 0.8606 - precision: 0.8607 - recall: 0.8623\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3168 - accuracy: 0.8651 - precision: 0.8647 - recall: 0.8674\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3026 - accuracy: 0.8723 - precision: 0.8717 - recall: 0.8747\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2871 - accuracy: 0.8822 - precision: 0.8828 - recall: 0.8828\n",
            "250/250 [==============================] - 50s 198ms/step - loss: 0.2557 - accuracy: 0.8942 - precision: 0.9342 - recall: 0.8459\n",
            "Try adam learning rate of: 0.007 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 198ms/step - loss: 0.4874 - accuracy: 0.8162 - precision: 0.8249 - recall: 0.8022\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3472 - accuracy: 0.8521 - precision: 0.8512 - recall: 0.8553\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3266 - accuracy: 0.8607 - precision: 0.8594 - recall: 0.8642\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3102 - accuracy: 0.8677 - precision: 0.8671 - recall: 0.8702\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2923 - accuracy: 0.8764 - precision: 0.8783 - recall: 0.8755\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2526 - accuracy: 0.8972 - precision: 0.8709 - recall: 0.9303\n",
            "Try adam learning rate of: 0.007 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 76s 198ms/step - loss: 0.5372 - accuracy: 0.7946 - precision: 0.7838 - recall: 0.8133\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3920 - accuracy: 0.8275 - precision: 0.8256 - recall: 0.8328\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3561 - accuracy: 0.8488 - precision: 0.8475 - recall: 0.8528\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3280 - accuracy: 0.8578 - precision: 0.8566 - recall: 0.8614\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3271 - accuracy: 0.8612 - precision: 0.8605 - recall: 0.8639\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2904 - accuracy: 0.8785 - precision: 0.9361 - recall: 0.8098\n",
            "Try adam learning rate of: 0.007 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 198ms/step - loss: 0.6303 - accuracy: 0.7386 - precision: 0.7465 - recall: 0.7219\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4877 - accuracy: 0.7872 - precision: 0.7799 - recall: 0.8034\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4374 - accuracy: 0.8079 - precision: 0.8033 - recall: 0.8183\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3966 - accuracy: 0.8327 - precision: 0.8302 - recall: 0.8387\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 199ms/step - loss: 0.3781 - accuracy: 0.8410 - precision: 0.8396 - recall: 0.8452\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.3327 - accuracy: 0.8725 - precision: 0.8619 - recall: 0.8841\n",
            "Try adam learning rate of: 0.008 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4500 - accuracy: 0.8256 - precision: 0.8199 - recall: 0.8342\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3409 - accuracy: 0.8547 - precision: 0.8545 - recall: 0.8568\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 199ms/step - loss: 0.3034 - accuracy: 0.8723 - precision: 0.8712 - recall: 0.8755\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3022 - accuracy: 0.8735 - precision: 0.8730 - recall: 0.8758\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2849 - accuracy: 0.8815 - precision: 0.8800 - recall: 0.8850\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2457 - accuracy: 0.8990 - precision: 0.9207 - recall: 0.8709\n",
            "Try adam learning rate of: 0.008 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4603 - accuracy: 0.8296 - precision: 0.8354 - recall: 0.8208\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3354 - accuracy: 0.8582 - precision: 0.8568 - recall: 0.8619\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3160 - accuracy: 0.8670 - precision: 0.8675 - recall: 0.8681\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 74s 199ms/step - loss: 0.3110 - accuracy: 0.8694 - precision: 0.8697 - recall: 0.8707\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2925 - accuracy: 0.8776 - precision: 0.8787 - recall: 0.8777\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2422 - accuracy: 0.9013 - precision: 0.9177 - recall: 0.8793\n",
            "Try adam learning rate of: 0.008 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4983 - accuracy: 0.8174 - precision: 0.8200 - recall: 0.8130\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3411 - accuracy: 0.8572 - precision: 0.8561 - recall: 0.8606\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3269 - accuracy: 0.8591 - precision: 0.8581 - recall: 0.8623\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3078 - accuracy: 0.8717 - precision: 0.8718 - recall: 0.8732\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2899 - accuracy: 0.8783 - precision: 0.8789 - recall: 0.8790\n",
            "250/250 [==============================] - 52s 199ms/step - loss: 0.2463 - accuracy: 0.8982 - precision: 0.9217 - recall: 0.8681\n",
            "Try adam learning rate of: 0.008 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4904 - accuracy: 0.8206 - precision: 0.8270 - recall: 0.8105\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3403 - accuracy: 0.8575 - precision: 0.8563 - recall: 0.8611\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3193 - accuracy: 0.8651 - precision: 0.8636 - recall: 0.8689\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3050 - accuracy: 0.8708 - precision: 0.8696 - recall: 0.8740\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3117 - accuracy: 0.8704 - precision: 0.8709 - recall: 0.8714\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2613 - accuracy: 0.8899 - precision: 0.9370 - recall: 0.8335\n",
            "Try adam learning rate of: 0.008 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.5215 - accuracy: 0.7984 - precision: 0.8110 - recall: 0.7777\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3755 - accuracy: 0.8383 - precision: 0.8373 - recall: 0.8420\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3468 - accuracy: 0.8508 - precision: 0.8499 - recall: 0.8541\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3251 - accuracy: 0.8653 - precision: 0.8655 - recall: 0.8669\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3165 - accuracy: 0.8670 - precision: 0.8669 - recall: 0.8689\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2719 - accuracy: 0.8873 - precision: 0.9214 - recall: 0.8442\n",
            "Try adam learning rate of: 0.008 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.6195 - accuracy: 0.7460 - precision: 0.7502 - recall: 0.7371\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4793 - accuracy: 0.7866 - precision: 0.7844 - recall: 0.7936\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4223 - accuracy: 0.8187 - precision: 0.8152 - recall: 0.8268\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3923 - accuracy: 0.8349 - precision: 0.8292 - recall: 0.8458\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3666 - accuracy: 0.8431 - precision: 0.8398 - recall: 0.8500\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.3375 - accuracy: 0.8616 - precision: 0.8165 - recall: 0.9293\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 1e-06 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4685 - accuracy: 0.8081 - precision: 0.7914 - recall: 0.8365\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3219 - accuracy: 0.8637 - precision: 0.8665 - recall: 0.8616\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3008 - accuracy: 0.8744 - precision: 0.8744 - recall: 0.8760\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3104 - accuracy: 0.8696 - precision: 0.8695 - recall: 0.8714\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.2902 - accuracy: 0.8777 - precision: 0.8782 - recall: 0.8785\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2504 - accuracy: 0.8947 - precision: 0.9306 - recall: 0.8507\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 1e-05 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4737 - accuracy: 0.8289 - precision: 0.8380 - recall: 0.8153\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3429 - accuracy: 0.8537 - precision: 0.8522 - recall: 0.8576\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3184 - accuracy: 0.8639 - precision: 0.8630 - recall: 0.8669\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3004 - accuracy: 0.8765 - precision: 0.8766 - recall: 0.8780\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2948 - accuracy: 0.8741 - precision: 0.8733 - recall: 0.8767\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2511 - accuracy: 0.8964 - precision: 0.9372 - recall: 0.8474\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 0.0001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4593 - accuracy: 0.8328 - precision: 0.8464 - recall: 0.8130\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3337 - accuracy: 0.8600 - precision: 0.8606 - recall: 0.8609\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3181 - accuracy: 0.8650 - precision: 0.8644 - recall: 0.8676\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3104 - accuracy: 0.8721 - precision: 0.8740 - recall: 0.8712\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2999 - accuracy: 0.8751 - precision: 0.8758 - recall: 0.8757\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2833 - accuracy: 0.8854 - precision: 0.8317 - recall: 0.9634\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 0.001 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.4826 - accuracy: 0.8128 - precision: 0.7941 - recall: 0.8443\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3584 - accuracy: 0.8443 - precision: 0.8441 - recall: 0.8465\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3200 - accuracy: 0.8633 - precision: 0.8630 - recall: 0.8654\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2984 - accuracy: 0.8769 - precision: 0.8754 - recall: 0.8805\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.2919 - accuracy: 0.8814 - precision: 0.8828 - recall: 0.8812\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2745 - accuracy: 0.8859 - precision: 0.9482 - recall: 0.8138\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 0.01 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.5235 - accuracy: 0.7943 - precision: 0.8090 - recall: 0.7701\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3766 - accuracy: 0.8320 - precision: 0.8303 - recall: 0.8369\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3427 - accuracy: 0.8541 - precision: 0.8540 - recall: 0.8561\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3469 - accuracy: 0.8504 - precision: 0.8522 - recall: 0.8498\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3213 - accuracy: 0.8638 - precision: 0.8648 - recall: 0.8642\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.2921 - accuracy: 0.8776 - precision: 0.9427 - recall: 0.8015\n",
            "Try adam learning rate of: 0.009000000000000001 and e: 0.1 and batch size: 32\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 77s 199ms/step - loss: 0.6077 - accuracy: 0.7494 - precision: 0.7630 - recall: 0.7228\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4745 - accuracy: 0.7842 - precision: 0.7810 - recall: 0.7931\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4111 - accuracy: 0.8228 - precision: 0.8198 - recall: 0.8301\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3901 - accuracy: 0.8282 - precision: 0.8244 - recall: 0.8366\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3621 - accuracy: 0.8469 - precision: 0.8442 - recall: 0.8530\n",
            "250/250 [==============================] - 51s 199ms/step - loss: 0.3240 - accuracy: 0.8689 - precision: 0.9006 - recall: 0.8262\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "EPOCHS = 5\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "\n",
        "\n",
        "lr_values = np.arange(1e-3, 1e-2, 0.001)\n",
        "epsilon_values = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "batch_values = [32]\n",
        "\n",
        "values = list(itertools.product(lr_values, epsilon_values, batch_values))\n",
        "\n",
        "print(f\"Combinations: {len(values)}\")\n",
        "for lr, ep, batch in values:\n",
        "  model: tf.keras.Model = build_model()\n",
        "\n",
        "  print(f\"Try adam learning rate of: {lr} and e: {ep} and batch size: {batch}\")\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr, epsilon=ep),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=METRICS)\n",
        "    \n",
        "  model.fit(X_train_sampled, y_train_sampled, epochs=EPOCHS, batch_size=batch)\n",
        "  model.evaluate(X_test_sampled, y_test_sampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of learning rate and epsilon\n",
        "After running the grid search for different learning rate values with 20k samples for 5 epochs, we get the following results. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "    Try adam learning rate of: 0.001 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8656 - precision: 0.8964 - recall: 0.8237\n",
        "    Try adam learning rate of: 0.001 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8634 - precision: 0.9016 - recall: 0.8126\n",
        "    Try adam learning rate of: 0.001 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8676 - precision: 0.9010 - recall: 0.8229\n",
        "    Try adam learning rate of: 0.001 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8744 - precision: 0.8774 - recall: 0.8674\n",
        "    Try adam learning rate of: 0.001 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8439 - precision: 0.9033 - recall: 0.7666\n",
        "    Try adam learning rate of: 0.001 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8291 - precision: 0.8127 - recall: 0.8507\n",
        "    Try adam learning rate of: 0.002 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8875 - precision: 0.8883 - recall: 0.8838\n",
        "    Try adam learning rate of: 0.002 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8826 - precision: 0.8503 - recall: 0.9257\n",
        "    Try adam learning rate of: 0.002 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8857 - precision: 0.8647 - recall: 0.9118\n",
        "    Try adam learning rate of: 0.002 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8838 - precision: 0.8753 - recall: 0.8921\n",
        "    Try adam learning rate of: 0.002 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8677 - precision: 0.8276 - recall: 0.9255\n",
        "    Try adam learning rate of: 0.002 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8446 - precision: 0.8258 - recall: 0.8694\n",
        "    Try adam learning rate of: 0.003 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8919 - precision: 0.8762 - recall: 0.9101\n",
        "    Try adam learning rate of: 0.003 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8917 - precision: 0.9028 - recall: 0.8755\n",
        "    Try adam learning rate of: 0.003 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8842 - precision: 0.8444 - recall: 0.9391\n",
        "    Try adam learning rate of: 0.003 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8903 - precision: 0.9013 - recall: 0.8740\n",
        "    Try adam learning rate of: 0.003 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8841 - precision: 0.8852 - recall: 0.8800\n",
        "    Try adam learning rate of: 0.003 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8531 - precision: 0.8754 - recall: 0.8199\n",
        "    Try adam learning rate of: 0.004 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8866 - precision: 0.9311 - recall: 0.8325\n",
        "    Try adam learning rate of: 0.004 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8830 - precision: 0.8373 - recall: 0.9477\n",
        "    Try adam learning rate of: 0.004 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8971 - precision: 0.9052 - recall: 0.8848\n",
        "    Try adam learning rate of: 0.004 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8953 - precision: 0.8807 - recall: 0.9118\n",
        "    Try adam learning rate of: 0.004 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8864 - precision: 0.8882 - recall: 0.8813\n",
        "    Try adam learning rate of: 0.004 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8602 - precision: 0.8298 - recall: 0.9028\n",
        "    Try adam learning rate of: 0.005 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8754 - precision: 0.8184 - recall: 0.9616\n",
        "    Try adam learning rate of: 0.005 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8775 - precision: 0.9474 - recall: 0.7967\n",
        "    Try adam learning rate of: 0.005 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8891 - precision: 0.9298 - recall: 0.8394\n",
        "    Try adam learning rate of: 0.005 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8972 - precision: 0.8934 - recall: 0.8997\n",
        "    Try adam learning rate of: 0.005 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8873 - precision: 0.8688 - recall: 0.9096\n",
        "    Try adam learning rate of: 0.005 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8644 - precision: 0.8453 - recall: 0.8886\n",
        "    Try adam learning rate of: 0.006 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8219 - precision: 0.7411 - recall: 0.9838\n",
        "    Try adam learning rate of: 0.006 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8846 - precision: 0.9486 - recall: 0.8108\n",
        "    Try adam learning rate of: 0.006 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.9013 - precision: 0.9047 - recall: 0.8947\n",
        "    Try adam learning rate of: 0.006 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.7896 - precision: 0.9814 - recall: 0.5860\n",
        "    Try adam learning rate of: 0.006 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8873 - precision: 0.8529 - recall: 0.9331\n",
        "    Try adam learning rate of: 0.006 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8700 - precision: 0.8587 - recall: 0.8825\n",
        "Try adam learning rate of: 0.007 and e: 1e-06 and batch size: 32\n",
        "> accuracy: 0.9038 - precision: 0.8971 - recall: 0.9098\n",
        "    Try adam learning rate of: 0.007 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8845 - precision: 0.8837 - recall: 0.8870\n",
        "    accuracy: 0.9019 - precision: 0.8795 - recall: 0.9290\n",
        "    Try adam learning rate of: 0.007 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8942 - precision: 0.9342 - recall: 0.8459\n",
        "    Try adam learning rate of: 0.007 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8972 - precision: 0.8709 - recall: 0.9303\n",
        "    Try adam learning rate of: 0.007 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8785 - precision: 0.9361 - recall: 0.8098\n",
        "    Try adam learning rate of: 0.007 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8725 - precision: 0.8619 - recall: 0.8841\n",
        "    Try adam learning rate of: 0.008 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8990 - precision: 0.9207 - recall: 0.8709\n",
        "    Try adam learning rate of: 0.008 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.9013 - precision: 0.9177 - recall: 0.8793\n",
        "    Try adam learning rate of: 0.008 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8982 - precision: 0.9217 - recall: 0.8681\n",
        "    Try adam learning rate of: 0.008 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8899 - precision: 0.9370 - recall: 0.8335\n",
        "    Try adam learning rate of: 0.008 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8873 - precision: 0.9214 - recall: 0.8442\n",
        "    Try adam learning rate of: 0.008 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8616 - precision: 0.8165 - recall: 0.9293\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 1e-06 and batch size: 32\n",
        "    accuracy: 0.8947 - precision: 0.9306 - recall: 0.8507\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 1e-05 and batch size: 32\n",
        "    accuracy: 0.8964 - precision: 0.9372 - recall: 0.8474\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 0.0001 and batch size: 32\n",
        "    accuracy: 0.8854 - precision: 0.8317 - recall: 0.9634\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 0.001 and batch size: 32\n",
        "    accuracy: 0.8859 - precision: 0.9482 - recall: 0.8138\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 0.01 and batch size: 32\n",
        "    accuracy: 0.8776 - precision: 0.9427 - recall: 0.8015\n",
        "    Try adam learning rate of: 0.009000000000000001 and e: 0.1 and batch size: 32\n",
        "    accuracy: 0.8689 - precision: 0.9006 - recall: 0.8262\n",
        "```\n",
        "\n",
        "> The best results are reached for a learning rate of 0.007 and an epsilon of 1e-06."
      ],
      "metadata": {
        "id": "lN1d7FjKCdy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Batch size\n",
        "\n",
        "Because the batch size is dependend on the data set size we had to run the grid search on the 200k data set. \n",
        "\n",
        "We used the optimized learning rate and episolon value from above."
      ],
      "metadata": {
        "id": "sCq_kkzYE_cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "EPOCHS = 5\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.0007\n",
        "ADAM_EPSILON = 1e-06\n",
        "\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "\n",
        "batch_values = [128] # [32, 38, 64, 128, 256, 512]\n",
        "\n",
        "for batch in batch_values:\n",
        "  model: tf.keras.Model = build_model()\n",
        "\n",
        "  print(f\"Try batch size: {batch}\")\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=ADAM_LEARNING_RATE, epsilon=ADAM_EPSILON),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=METRICS)\n",
        "    \n",
        "  model.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch)\n",
        "  model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ooje1SFO_l",
        "outputId": "263effba-e65f-4cc0-f3d2-85dc9be56525"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try batch size: 128\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 938s 991ms/step - loss: 0.5430 - accuracy: 0.7423 - precision: 0.7408 - recall: 0.7441\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 932s 993ms/step - loss: 0.3794 - accuracy: 0.8501 - precision: 0.8486 - recall: 0.8515\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 931s 992ms/step - loss: 0.3317 - accuracy: 0.8683 - precision: 0.8672 - recall: 0.8691\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 929s 991ms/step - loss: 0.3086 - accuracy: 0.8770 - precision: 0.8761 - recall: 0.8776\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 930s 991ms/step - loss: 0.2948 - accuracy: 0.8810 - precision: 0.8804 - recall: 0.8813\n",
            "2500/2500 [==============================] - 490s 196ms/step - loss: 0.2720 - accuracy: 0.8965 - precision: 0.8673 - recall: 0.9370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "EPOCHS = 5\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.0007\n",
        "ADAM_EPSILON = 1e-06\n",
        "\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "\n",
        "batch_values = [512] # [32, 38, 64, 128, 256, 512]\n",
        "\n",
        "for batch in batch_values:\n",
        "  model: tf.keras.Model = build_model()\n",
        "\n",
        "  print(f\"Try batch size: {batch}\")\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=ADAM_LEARNING_RATE, epsilon=ADAM_EPSILON),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=METRICS)\n",
        "    \n",
        "  model.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch)\n",
        "  model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "SSEDMrIXEYUT",
        "outputId": "d765492e-e421-4656-b374-00cbaceee07d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try batch size: 512\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 1949s 8s/step - loss: 0.6083 - accuracy: 0.6828 - precision: 0.6796 - recall: 0.6892\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 1947s 8s/step - loss: 0.4847 - accuracy: 0.8055 - precision: 0.8028 - recall: 0.8091\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 1947s 8s/step - loss: 0.4245 - accuracy: 0.8334 - precision: 0.8306 - recall: 0.8369\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 1950s 8s/step - loss: 0.3911 - accuracy: 0.8450 - precision: 0.8418 - recall: 0.8488\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 1951s 8s/step - loss: 0.3653 - accuracy: 0.8539 - precision: 0.8520 - recall: 0.8558\n",
            "2500/2500 [==============================] - 491s 196ms/step - loss: 0.3360 - accuracy: 0.8771 - precision: 0.8654 - recall: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate\n",
        "\n",
        "After training the model and evaluation the model for different batch sizes we come up with the following results. \n",
        "\n",
        "\n",
        "```\n",
        "    Try batch size: 32\n",
        "    accuracy: 0.9117 - precision: 0.9247 - recall: 0.8959\n",
        "    Try batch size: 48\n",
        "    accuracy: 0.9221 - precision: 0.9399 - recall: 0.9011\n",
        "Try batch size: 64\n",
        "accuracy: 0.9227 - precision: 0.9168 - recall: 0.9295\n",
        "    Try batch size: 128\n",
        "    accuracy: 0.8965 - precision: 0.8673 - recall: 0.9370\n",
        "    Try batch size: 256\n",
        "    accuracy: 0.9189 - precision: 0.9068 - recall: 0.9333\n",
        "    Try batch size: 512\n",
        "    accuracy: 0.8771 - precision: 0.8654 - recall: 0.8940\n",
        "```\n",
        "\n",
        "We managed to reach the highest score with batch size 64. Therefore we use this for the final training."
      ],
      "metadata": {
        "id": "Ho82a4l8GM58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BktqhHJSGk6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Kopie von ANN with BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7b4a9521aa94ee9b9eef12fd6096da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_740260148dd64d39896b2e9e0b625355",
              "IPY_MODEL_94638bdc749449aab6bc8b5695910f48",
              "IPY_MODEL_c33d539aa06543c1a06bd515eb37aea2"
            ],
            "layout": "IPY_MODEL_92d06e0207bf4a2da666030932fb22cf"
          }
        },
        "740260148dd64d39896b2e9e0b625355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60e5a0301064d50857dbfc85f691014",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0b8ed2145342e78bf6050f12c2d0ab",
            "value": "Downloading: 100%"
          }
        },
        "94638bdc749449aab6bc8b5695910f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21ed56c72994aa48c8514a175bf8ed1",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de109c73e744be393b7d2e6ba3cb812",
            "value": 213450
          }
        },
        "c33d539aa06543c1a06bd515eb37aea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677a8b56b75f4708b4c0c451f0196c90",
            "placeholder": "​",
            "style": "IPY_MODEL_16249a5f67fb497ea1b5a9600249611b",
            "value": " 208k/208k [00:00&lt;00:00, 300kB/s]"
          }
        },
        "92d06e0207bf4a2da666030932fb22cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60e5a0301064d50857dbfc85f691014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0b8ed2145342e78bf6050f12c2d0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f21ed56c72994aa48c8514a175bf8ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de109c73e744be393b7d2e6ba3cb812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "677a8b56b75f4708b4c0c451f0196c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16249a5f67fb497ea1b5a9600249611b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89004cadb6ba4b659789a0d9067f608f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58fe41ee7b5e4b68b4250c2a37e5d9c0",
              "IPY_MODEL_da96936c40674aa48d0c1b08e0c903da",
              "IPY_MODEL_1f61b4c3deac46afa7260d198de789df"
            ],
            "layout": "IPY_MODEL_492134850a2c4bd8bcf2f3113b385981"
          }
        },
        "58fe41ee7b5e4b68b4250c2a37e5d9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68f2b06a8f354e61a9ca24777ee59896",
            "placeholder": "​",
            "style": "IPY_MODEL_844db5015fdf4c939ade055e6bc16504",
            "value": "Downloading: 100%"
          }
        },
        "da96936c40674aa48d0c1b08e0c903da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a05d0855cadd480bbc2029631a1a7f1d",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83dd64e052ce4a3f85d05bef0e3b0802",
            "value": 29
          }
        },
        "1f61b4c3deac46afa7260d198de789df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae5e7deafb44a488f772098c869fde3",
            "placeholder": "​",
            "style": "IPY_MODEL_beeec6138afb47d1b4cbf776c22ef709",
            "value": " 29.0/29.0 [00:00&lt;00:00, 626B/s]"
          }
        },
        "492134850a2c4bd8bcf2f3113b385981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f2b06a8f354e61a9ca24777ee59896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844db5015fdf4c939ade055e6bc16504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a05d0855cadd480bbc2029631a1a7f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83dd64e052ce4a3f85d05bef0e3b0802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cae5e7deafb44a488f772098c869fde3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beeec6138afb47d1b4cbf776c22ef709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89de322b266f445ba47195a7315d8bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b099cf64eec842b386ef955c34270735",
              "IPY_MODEL_fbec7d3e9d644686ba733a983544f48f",
              "IPY_MODEL_17dcbdeb96614310abbd76aaa6e50e15"
            ],
            "layout": "IPY_MODEL_9ffdf04cfbab4b62a5aebe7381aefad9"
          }
        },
        "b099cf64eec842b386ef955c34270735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a962b96b834449e7812b1ebd9b1d67fc",
            "placeholder": "​",
            "style": "IPY_MODEL_d049288f11ee437b952ca16e8c0a9670",
            "value": "Downloading: 100%"
          }
        },
        "fbec7d3e9d644686ba733a983544f48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e12044033be4fceab9f59836157cc8c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20208cdbe6634e4d81fbbf2f11eeec92",
            "value": 570
          }
        },
        "17dcbdeb96614310abbd76aaa6e50e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e21028de82483188cd497ef8ef9e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_ced37242f1f74347a6ff66e9ea165bdc",
            "value": " 570/570 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "9ffdf04cfbab4b62a5aebe7381aefad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a962b96b834449e7812b1ebd9b1d67fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d049288f11ee437b952ca16e8c0a9670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e12044033be4fceab9f59836157cc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20208cdbe6634e4d81fbbf2f11eeec92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61e21028de82483188cd497ef8ef9e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced37242f1f74347a6ff66e9ea165bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}