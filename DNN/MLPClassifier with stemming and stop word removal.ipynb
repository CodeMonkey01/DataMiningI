{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8174a30f",
   "metadata": {},
   "source": [
    "# MLPClassifier with Stemming and Stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f19ce",
   "metadata": {},
   "source": [
    "In this notebook, we try predicting humor based on the MLPClassifier, aided by stemming and stop word removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f7794",
   "metadata": {},
   "source": [
    "Results:\n",
    "----\n",
    "Hidden_layer_sizes=(150,100,50) ==> 0.8242 accuracy\n",
    "----\n",
    "Hidden_layer_sizes=(100,80,60) ==> 0.820825 accuracy\n",
    "----\n",
    "Hidden_layer_sizes=(150,100,75) ==> 0.820825 accuracy\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018de2c6",
   "metadata": {},
   "source": [
    "General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c449f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07322b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#when running for the first time you need to activate this line for once.\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Data Preprocessing, turn the \"humor\" column into boolean \n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "le = LabelEncoder()\n",
    "df[\"humor\"] = le.fit_transform(df[\"humor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38039d57",
   "metadata": {},
   "source": [
    "Encoding the first column with int values instead of boolean and a function to remove stop words and stem the strings that pass in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data Preprocessing, turn the \"humor\" column into boolean \n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "le = LabelEncoder()\n",
    "df[\"humor\"] = le.fit_transform(df[\"humor\"])\n",
    "\n",
    "\n",
    "#definition of stemming function\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\") # split on whitespace\n",
    "\n",
    "def tokenize(text):\n",
    "    my_stopwords = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    \n",
    "    tokens = token_pattern.findall(text)\n",
    "    for item in tokens:\n",
    "        if item not in my_stopwords:\n",
    "            stems.append(stemmer.stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea2ac2",
   "metadata": {},
   "source": [
    "Turning the stemmed text data into a TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df=0.0015)\n",
    "matrix = stem_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "df_data_stemmed = pd.DataFrame(matrix.toarray(), columns=stem_vectorizer.get_feature_names_out())\n",
    "display(df_data_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f057a",
   "metadata": {},
   "source": [
    "Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54828765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train, df_data_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_data_stemmed, df[\"humor\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367a58e",
   "metadata": {},
   "source": [
    "A method to calculate the accuracy based on the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "   diagonal_sum = confusion_matrix.trace()\n",
    "   sum_of_all_elements = confusion_matrix.sum()\n",
    "   return diagonal_sum / sum_of_all_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305d150",
   "metadata": {},
   "source": [
    "Running the classifier, fitting the model and measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d57349",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "classifier = MLPClassifier(hidden_layer_sizes=i,max_iter=300\n",
    "                           ,activation = 'relu',solver='adam',random_state=1)\n",
    "classifier.fit(df_data_train, df_target_train)\n",
    "y_pred = classifier.predict(df_data_test)\n",
    "\n",
    "#Comparing the predictions against the actual observations in y_val\n",
    "cm = confusion_matrix(df_target_test,y_pred)\n",
    "asc = accuracy_score(df_target_test,y_pred)\n",
=======
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(50,),activation = 'relu',solver='adam',random_state=1,learning_rate=\"constant\",alpha=0.05)\n",
    "classifier.fit(df_data_train, df_target_train)\n",
    "y_pred = classifier.predict(df_data_test)\n",
    "\n",
    "#Comparing the predictions against the actual observations in y_val\n",
    "cm = confusion_matrix(df_target_test,y_pred)\n",
>>>>>>> Stashed changes
    "\n",
    "#Printing the accuracy\n",
    "print(cm)\n",
    "print(\"Accuracy of MLPClassifier : \")\n",
    "print(accuracy(cm))\n",
    "\n",
    "ax = sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Humor prediction with MLPClassifier\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "ps = precision_score(df_target_test,y_pred)\n",
    "rs = recall_score(df_target_test,y_pred)\n",
    "print(\"The precision score is \",ps,\"and recall is\",rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ef425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
