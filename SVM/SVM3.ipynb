{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d585852c",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## -> without removing stopwords, with stemming\n",
    "- Accuracy: around 0.86 for k=20 (up to 0.87 for k = 50)\n",
    "- F1-value:\n",
    "- Roc-curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa355e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "158403    False\n21409     False\n101663     True\n33287     False\n78317      True\nName: humor, dtype: bool"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(30000)\n",
    "df_target = df['humor']\n",
    "df_data = df.copy()\n",
    "df_data.drop(columns='humor')\n",
    "\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a08c5",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be314f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#encode target to numeric\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_target = label_encoder.fit_transform(df_target)\n",
    "#df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6efba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer created 142 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcl.NB-MCL\\anaconda3\\envs\\datamining\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Apply CountVectorizer on text column\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "#If this vectorizer is used, a word which occurs multiple times is counted and not just displayed as 1 = word occurs \n",
    "#cVectorizer = CountVectorizer(binary=False)\n",
    "\n",
    "#At the moment I am not able to apply the vectorizer on the whole dataset. To many records & less available RAM\n",
    "matrix = vectorizer.fit_transform(df_data['text'].head(15))\n",
    "\n",
    "print(\"Vectorizer created {} features.\".format(len(vectorizer.get_feature_names())))\n",
    "\n",
    "df_data_countVectorized = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "#display(df_data_countVectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5457550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, string\n",
    "\n",
    "#when running for the first time you need to activate this line for once.\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#definition of stemming function\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\") # split on whitespace\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    \n",
    "    tokens = token_pattern.findall(text)\n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236df96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm not sure if we agreed to use stemming or not. I'll store the results in another df\n",
    "#Stopwords are removed here as well\n",
    "stem_vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df=0.0015)\n",
    "matrix = stem_vectorizer.fit_transform(df_data['text'])\n",
    "\n",
    "df_data_stemmed = pd.DataFrame(matrix.toarray(), columns=stem_vectorizer.get_feature_names())\n",
    "#display(df_data_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98c786",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea383871",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create train/test split\n",
    "df_data_train, df_data_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_data_stemmed, df_target, test_size=0.2, random_state=42)\n",
    "\n",
    "#dt = DecisionTreeClassifier()\n",
    "#dt.fit(df_data_train, df_target_train)\n",
    "\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(df_data_train, df_target_train)\n",
    "\n",
    "df_prediction = svm.predict(df_data_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(df_target_test, df_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcdbdfa",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "cnf_matrix = confusion_matrix(df_target_test, df_prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14309474",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}